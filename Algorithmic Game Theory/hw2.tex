\documentclass[a4paper,12pt]{article}
\setlength{\parindent}{0cm}
\usepackage{amsmath, amssymb, amsthm, mathtools,pgfplots}
\usepackage{graphicx,caption}
\usepackage{verbatim}
\usepackage{venndiagram}
\usepackage[cm]{fullpage}
\usepackage{fancyhdr}
\usepackage{tikz,multirow}
\usepackage{listings}
\usepackage{color,enumerate,framed}
\usepackage{color,hyperref}
\definecolor{darkblue}{rgb}{0.0,0.0,0.5}
\hypersetup{colorlinks,breaklinks,
            linkcolor=darkblue,urlcolor=darkblue,
            anchorcolor=darkblue,citecolor=darkblue}

%\usepackage{tgadventor}
%\usepackage[nohug]{diagrams}
\usepackage[T1]{fontenc}
%\usepackage{helvet}
%\renewcommand{\familydefault}{\sfdefault}
%\usepackage{parskip}
%\usepackage{picins} %for \parpic.
%\newtheorem*{notation}{Notation}
%\newtheorem{example}{Example}[section]
%\newtheorem*{problem}{Problem}
\theoremstyle{definition}
%\newtheorem{theorem}{Theorem}
%\newtheorem*{solution}{Solution}
%\newtheorem*{definition}{Definition}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem*{remark}{Remark}
%\setcounter{section}{1}

\newtheorem{thm}{Theorem}[section]
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
%\newtheorem{defn}[thm]{Definition}
\newtheorem*{defn}{Definition}
\newtheorem*{examp}{Example}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{rmk}[thm]{Remark}
\newtheorem*{nte}{Note}
\newtheorem*{notat}{Notation}
%\pgfplotset{compat=1.14}
%\diagramstyle[labelstyle=\scriptstyle]

\lstset{frame=tb,
  language=Oz,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\usepackage{floatrow}
% Table float box with bottom caption, box width adjusted to content
\newfloatcommand{capbtabbox}{table}[][\FBwidth]

\pagestyle{fancy}


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


\fancyhead{}
\renewcommand{\headrulewidth}{0pt}

\lfoot{}
\cfoot{}

%\lfoot{\color{black!60}{\sffamily Zhangsheng Lai}}
%\cfoot{\color{black!60}{\sffamily Last modified: \today}}
\rfoot{\textsc{\thepage}}



\begin{document}
\flushright{Manos \\Nguyen Tan Thai Hung\quad 1001986\\Zhangsheng Lai\quad1002554}
\section*{Algorithmic Game Theory: HW 2}

\begin{enumerate}

\item
Let $G$ be a cost-minimization game which has the function $\Phi$ such that
\begin{align*}
C_i(s'_i,s_{-i})&<C_i(s)\\
\Phi(s'_i,s_{-i})&<\Phi(s)
\end{align*}
As the game is finite, we can use $\Phi$ and best-response dynamics such that the cost decreases with every beneficial deviation made by a particular agent until no more beneficial deviation exists for every agent and call this strategy $s^\ast$. Then this $s^\ast$ is a pure Nash since for any agent $i$ and any deviation $s'_i$, we cannot have
\begin{align*}
C_i(s'_i,s_{-i})<C_i(s^\ast)
\end{align*}
since it implies $\Phi(s'_i,s_{-i})<\Phi(s^\ast)$ and contradicts $\Phi(s^\ast)<\Phi(s)$ for all pure strategies $s \neq s^\ast$. Thus this game has at least one PNE.
\item
\begin{enumerate}[(a)]
\item 
Consider the utility maximizing game below starting with the the initial outcome $(A_1,B_1)$, from which best-response dynamics cycles forever, avoiding the pure Nash of $(A_3,B_2)$.
\begin{figure}[h]
\renewcommand{\arraystretch}{1.5}
    \centering
    \begin{tabular}{cc|c|c|c|}
      & \multicolumn{1}{c}{} & \multicolumn{3}{c}{P$1$}\\
      & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$A_1$}  & \multicolumn{1}{c}{$A_2$} &\multicolumn{1}{c}{$A_3$}\\\cline{3-5}
      \multirow{3}*{P$2$}  & $B_1$ & $1,4$ & $2,3$& $0,0$\\\cline{3-5}
      \cline{3-5}
& $B_2$ & $0,0$ & $0,0$& $5,5$\\\cline{3-5}
      & $B_3$ & $4,1$ & $3,2$ &$0,0$\\\cline{3-5}
    \end{tabular}
 \end{figure}   

%\begin{figure}[h]
%\renewcommand{\arraystretch}{1.5}
%    \centering
%    \begin{tabular}{cc|c|c|c|}
%      & \multicolumn{1}{c}{} & \multicolumn{3}{c}{P$1$}\\
%      & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$A_1$}  & \multicolumn{1}{c}{$A_2$} &\multicolumn{1}{c}{$A_3$}\\\cline{3-5}
%      \multirow{3}*{P$2$}  & $B_1$ & $4,1$ & $1,2$& $0,0$\\\cline{3-5}
%      \cline{3-5}
%& $B_2$ & $0,0$ & $0,0$& $5,5$\\\cline{3-5}
%      & $B_3$ & $3,3$ & $3,2$ &$0,0$\\\cline{3-5}
%    \end{tabular}
% \end{figure}   
 \item Consider the cost minimization game below, where for player P1, weights are decreased whenever $A_1$ or $A_2$ is played. Thus the weights are concentrated on $A_3$ in the long run and hence the time-averaged history of joint play would point to playing $A_3$ with close to 1 probability. Similar argument goes for P2 and thus average history of joint play will point to $A_3,B_3$ being the PNE.
 
 \begin{figure}[h]
\renewcommand{\arraystretch}{1.5}
    \centering
    \begin{tabular}{cc|c|c|c|}
      & \multicolumn{1}{c}{} & \multicolumn{3}{c}{P$1$}\\
      & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$A_1$}  & \multicolumn{1}{c}{$A_2$} &\multicolumn{1}{c}{$A_3$}\\\cline{3-5}
      \multirow{3}*{P$2$}  & $B_1$ & $1,1$ & $1,1$& $0,0$\\\cline{3-5}
      \cline{3-5}
& $B_2$ & $1,1$ & $1,1$& $0,0$\\\cline{3-5}
      & $B_3$ & $0,0$ & $0,0$ &$0,0$\\\cline{3-5}
    \end{tabular}
 \end{figure}   

 
\end{enumerate}

\item For a fixed $t'$ such that $i$ is the smallest integer such that $t'\leq2^i$. Then $\epsilon=\sqrt{\frac{\ln n}{t'}}\geq\sqrt{\frac{\ln n}{2^i}}$ and the regret is at most $2\sqrt{2^i\ln n}$ up till time $t$, i.e.
\begin{align*}
\sum_{t=1}^{t'}\nu^t \leq OPT + 2\sqrt{2^i\ln n}
\end{align*}
Let $kt'\geq T$ for some integer $k$, then
\begin{align*}
\sum_{t=1}^{T}\nu^t \leq\sum_{t=1}^{kt'}\nu^t \leq OPT + k\cdot 2\sqrt{2^i\ln n}=OPT + (2\sqrt{k^2\cdot 2^i\ln n}) \leq OPT + 2\sqrt{k}\sqrt{T\ln n}
\end{align*}
and hence the expected regret is still $O(\sqrt{\ln n/T})$ with respect to every fixed action.
\item \label{eq:q4} Let $f_\epsilon(x)=(1-\epsilon)^x$ and $g_\epsilon(x)=1-\epsilon x$, then \label{eq:q4}
\begin{align*}
&f_\epsilon(0) = 1 = g_\epsilon(0)\\
&f_\epsilon(1) = 1-\epsilon = g_\epsilon(1)\\
&\begin{rcases}
 f'_\epsilon(x)&=(1-\epsilon)^x\ln (1-\epsilon) \\
  g'_\epsilon(x)&=-\epsilon \\
\end{rcases}f'_\epsilon(0) = \ln(1-\epsilon) < -\epsilon= g'_\epsilon(0)
\end{align*}
The last inequality holds since
\begin{align*}
\ln(1-\epsilon)=-\epsilon -\frac{\epsilon^2}{2!(1-\xi)^2}\quad \text{by Taylor's theorem in Lagrange form}
\end{align*}
for some $\xi \in (0,\epsilon)$. Also $f_\epsilon$ is a convex function as $f''_\epsilon(x)=(1-\epsilon)^x\left[\ln (1-\epsilon)\right]^2>0$ for $\epsilon \in(0,1/2]$ on the interval $[0,1]$. This this proves $f_\epsilon(x)\leq g_\epsilon(x)$.

Let $\hat{f}_\epsilon(x)=(1+\epsilon)^x$, then by Taylor's expansion  %$\hat{g}_\epsilon(x)$ 
\begin{align*}
(1+\epsilon)^x = 1 + \epsilon x + \frac{x(x-1)(1-\xi)^{x-2}}{2!}\epsilon^2
\end{align*}
for some $\xi \in (0,\epsilon)$. We observe that $\frac{x(x-1)(1-\xi)^{x-2}}{2!}\epsilon^2 \leq 0$ since $x \in [0,1]$ we have proved that $(1+\epsilon)^x \leq 1+\epsilon x$.
%Let $f(\epsilon,x)=(1-\epsilon)^x$, then
%\begin{align*}
%\frac{f^{n}(\epsilon,x)}{d\epsilon^n}=(-1)^n\cdot x(x-1)(x-2)\ldots(x-n+1)(1-\epsilon)^{x-n}
%\end{align*}
%Doing Maclaurin series on $f(\epsilon,x)$ for a fixed $x \in [0,1]$ with respect to $\epsilon$, we get:
%\begin{align*}
%(1-\epsilon)^x&=\sum_{n=0}^{\infty}(-1)^n\frac{x(x-1)(x-2)\ldots(x-n+1)}{n!}\epsilon^n\\
%&=1-\epsilon x + \sum_{n=2}^{\infty}(-1)^n\frac{x(x-1)(x-2)\ldots(x-n+1)}{n!}\epsilon^n
%\end{align*}
%To prove the inequality, it suffices to prove that 
%\begin{align*}
%\sum_{n=2}^{\infty}(-1)^n\frac{x(x-1)(x-2)\ldots(x-n+1)}{n!}\epsilon^n \leq 0
%\end{align*}
%which is true since $(-1)^n\cdot x(x-1)(x-2)\ldots(x-n+1) = -x (1-x)(2-x)\ldots (n-1-x)\leq 0$.
\item Consider the online decision-making setting where every time step $t$ the adversary  chooses a payoff vector $\pi^t:A \to [0,1]$ where the time-averaged regret is defined as $\frac{1}{T} \max_{a\in A}\sum_{t=1}^{T}\pi^t(a)-\frac{1}{T}\sum_{t=1}^{T}\pi^t(a^t)$. Let $\Gamma^t =\sum_{a\in A}w^t(a)$ and define $OPT = \sum_{t=1}^{T}c^t(a^\ast)$ as the cumulative cost for the best fixed action $a^\ast$. Then
\begin{align*}
\Gamma^T&\leq w^T(a^\ast)\\
&=w^1(a^\ast)\prod_{t=1}^{T}(1+\epsilon)^{\pi^t(a^\ast)} = (1+\epsilon)^{OPT}
\end{align*}
Te expectec cost of the MW algorithm at time $t$ is 
\begin{align*}
\sum_{a \in A}p^t(a).\pi^t(a) = \sum_{a \in A}\frac{w^t(a)}{\Gamma^t}\pi^t(a) 
\end{align*}
We can rewrite $\Gamma^{t+1}$ in terms of $\Gamma^t$ in the following manner
\begin{align*}
\Gamma^{t+1} &= \sum_{a \in A}w^{t+1}(a)\\
&= \sum_{a \in A}w^{t}(a)\cdot (1+\epsilon)^{\pi^t(a)}\\
&\leq \sum_{a \in A}w^{t}(a)\cdot (1+\epsilon\pi^t(a)) \quad \text{by Q\ref{eq:q4}}\\
&\leq \Gamma^t\sum_{a \in A}p^{t}(a)\cdot (1+\epsilon\pi^t(a))\\
&\leq \Gamma^t\sum_{a \in A}p^{t}(a)+p^{t}(a)\epsilon\pi^t(a)\\
&\leq \Gamma^t(1+\epsilon\nu^t)\quad \text{where $\nu^t$ is the expected utility at time $t$.}
\end{align*}
Combining the results obtained from before,
\begin{align*}
(1+\epsilon)^{OPT}&\leq \Gamma^T\leq \Gamma^1\prod_{t=1}^{T}(1+\epsilon \nu^t)\\
OPT \ln (1+\epsilon)&\leq  \ln n + \sum_{t=1}^{T}\ln (1+\epsilon \nu^t)\\
OPT (\epsilon-\epsilon^2)\leq OPT \ln (1+\epsilon)&\leq  \ln n + \sum_{t=1}^{T}\ln (1+\epsilon \nu^t)\leq  \ln n + \sum_{t=1}^{T}\epsilon \nu^t\\
OPT (\epsilon-\epsilon^2)&\leq   \ln n + \sum_{t=1}^{T}\epsilon \nu^t\\
OPT &\leq   (\ln n)/\epsilon + \sum_{t=1}^{T}\nu^t +\epsilon OPT\leq   (\ln n)/\epsilon +\epsilon T + \sum_{t=1}^{T}\nu^t \\
\end{align*}
Hence equalizing the two error terms, we get $\epsilon=\sqrt{\ln n/T}$, similar to the case of the cost vector. Thus it has regret $O(\sqrt{\ln n/T})$
\item 
\begin{enumerate}[(a)]
\item %$(\Rightarrow)$ 
Let $\hat{x}, \hat{y}$ be a mixed Nash equilibrium then,
\begin{align}
\hat{x}^TA\hat{y}&\geq x^TA\hat{y} \quad \text{for all mixed distributions $x$}\\
\hat{x}^TA\hat{y}&\leq \hat{x}^TAy \quad \text{for all mixed distributions $y$}
\end{align}
if and only if,
\begin{align*}
\hat{x}\in\argmax_x \left(x^TA \hat{y}\right)\subseteq\argmax_x\left(\min_yx^TAy\right)\\
\hat{y}\in\argmin_y \left(\hat{x}^T Ay\right)\subseteq\argmin_x\left(\max_xx^TAy\right)
\end{align*}

%$(\Leftarrow)$ 
\item Let $x_1,y_1$ and $x_2,y_2$ be the given mixed Nash equilibria of a two-player zero-sum game. Thus by the above result, for $i=1,2$
\begin{align*}
x_i &\in \argmax_x\left(\min_yx^TAy\right)\\
y_{3-i} & \in\argmin_x\left(\max_xx^TAy\right)
\end{align*}
thus
\begin{align*}
x_i^TAy_{3-i}&\geq x^TAy_{3-i} \quad \text{for all mixed distributions $x$}\\
x_i^TAy_{3-i}&\leq x_i^TAy_{} \quad \text{for all mixed distributions $y$}
\end{align*}
which by definition tells us that $(x_i,y_{3-i})$ is a mixed Nash equilibrium for $i=1,2$.
\end{enumerate}

\item
\begin{enumerate}[(a)]
\item Let $(A,B)$ be a given general bimatrix game with player one and player two having $n$ and $m$ different strategies to choose from their strategy set denoted by $\mathbf{x}$ and $\mathbf{y}$ respectively, thus $A$ and $B$ are $n \times m$ and $m \times n$ matrices respectively. The expected payoffs of player one is then  $\mathbf{x}^TA\mathbf{y}$ and the expected payoffs of player two is $\mathbf{y}^TB\mathbf{x}$.
\item
\end{enumerate}


\end{enumerate}






\end{document}