\documentclass[a4paper,12pt]{article}
\setlength{\parindent}{0cm}
\usepackage{amsmath, amssymb, amsthm, mathtools,pgfplots}
\usepackage{graphicx,caption}
\usepackage{verbatim}
\usepackage{venndiagram}
\usepackage[cm]{fullpage}
\usepackage{fancyhdr}
\usepackage{tikz,multirow}
\usepackage{listings}
\usepackage{color,enumerate,framed}
\usepackage{color,hyperref}
\definecolor{darkblue}{rgb}{0.0,0.0,0.5}
\hypersetup{colorlinks,breaklinks,
            linkcolor=darkblue,urlcolor=darkblue,
            anchorcolor=darkblue,citecolor=darkblue}

%\usepackage{tgadventor}
%\usepackage[nohug]{diagrams}
\usepackage[T1]{fontenc}
%\usepackage{helvet}
%\renewcommand{\familydefault}{\sfdefault}
%\usepackage{parskip}
%\usepackage{picins} %for \parpic.
%\newtheorem*{notation}{Notation}
%\newtheorem{example}{Example}[section]
%\newtheorem*{problem}{Problem}
\theoremstyle{definition}
%\newtheorem{theorem}{Theorem}
%\newtheorem*{solution}{Solution}
%\newtheorem*{definition}{Definition}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem*{remark}{Remark}
%\setcounter{section}{1}

\newtheorem{thm}{Theorem}[section]
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
%\newtheorem{defn}[thm]{Definition}
\newtheorem*{defn}{Definition}
\newtheorem*{examp}{Example}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{rmk}[thm]{Remark}
\newtheorem*{nte}{Note}
\newtheorem*{notat}{Notation}
%\pgfplotset{compat=1.14}
%\diagramstyle[labelstyle=\scriptstyle]

\lstset{frame=tb,
  language=Oz,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\usepackage{floatrow}
% Table float box with bottom caption, box width adjusted to content
\newfloatcommand{capbtabbox}{table}[][\FBwidth]

\pagestyle{fancy}


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


\fancyhead{}
\renewcommand{\headrulewidth}{0pt}

\lfoot{}
\cfoot{}

%\lfoot{\color{black!60}{\sffamily Zhangsheng Lai}}
%\cfoot{\color{black!60}{\sffamily Last modified: \today}}
\rfoot{\textsc{\thepage}}

\newcommand*{\tran}{^{\mkern-1.5mu\mathsf{T}}}

\begin{document}

\begin{flushright}
	Emmanouil Leontaris\quad 1001984
	
	Nguyen Tan Thai Hung\quad 1001986
	
	Zhangsheng Lai\quad1002554
\end{flushright}

\begin{center}
	\Huge{\bfseries Algorithmic Game Theory: HW 2}
\end{center}

\section*{Question 1}

Let $G$ be a cost-minimization game which admits the function $\Phi$ such that, for every outcome $s$, every player $i$, and every possible deviation $s'_i$
\begin{align} \label{eq:1}
	C_i(s'_i,s_{-i})&<C_i(s) \implies \Phi(s'_i,s_{-i}) <\Phi(s)
\end{align}
As the game is finite, a global minimum exists for $\Phi$ (not necessarily unique). Let $s^*$ denote an outcome at which $\Phi$ achieves its global minimum. If follows that $s^*$ has to be a pure Nash equilibrium, because if $s^*$ is not a PNE, then there exists an agent $i$ who can deviate from $s_i$ to $s'_i$ and hence $C_i(s'_i,s_{-i}) <C_i(s)$. This implies, following (\ref{eq:1}), that $\Phi(s'_i,s_{-i}) <\Phi(s)$, which contradicts the fact that $s$ is the global minimum. Therefore, a PNE always exist (and it corresponds to a global minimum of $\Phi$).

\section*{Question 2}
\begin{enumerate}[(a)]
\item 
Consider the utility maximizing game below starting with the the initial outcome $(A_1,B_1)$, from which best-response dynamics cycles forever, avoiding the pure Nash of $(A_3,B_2)$.
\begin{figure}[h]
\renewcommand{\arraystretch}{1.5}
    \centering
    \begin{tabular}{cc|c|c|c|}
      & \multicolumn{1}{c}{} & \multicolumn{3}{c}{P$1$}\\
      & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$A_1$}  & \multicolumn{1}{c}{$A_2$} &\multicolumn{1}{c}{$A_3$}\\\cline{3-5}
      \multirow{3}*{P$2$}  & $B_1$ & $1,4$ & $2,3$& $0,0$\\\cline{3-5}
      \cline{3-5}
& $B_2$ & $0,0$ & $0,0$& $5,5$\\\cline{3-5}
      & $B_3$ & $4,1$ & $3,2$ &$0,0$\\\cline{3-5}
    \end{tabular}
 \end{figure}   

%\begin{figure}[h]
%\renewcommand{\arraystretch}{1.5}
%    \centering
%    \begin{tabular}{cc|c|c|c|}
%      & \multicolumn{1}{c}{} & \multicolumn{3}{c}{P$1$}\\
%      & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$A_1$}  & \multicolumn{1}{c}{$A_2$} &\multicolumn{1}{c}{$A_3$}\\\cline{3-5}
%      \multirow{3}*{P$2$}  & $B_1$ & $4,1$ & $1,2$& $0,0$\\\cline{3-5}
%      \cline{3-5}
%& $B_2$ & $0,0$ & $0,0$& $5,5$\\\cline{3-5}
%      & $B_3$ & $3,3$ & $3,2$ &$0,0$\\\cline{3-5}
%    \end{tabular}
% \end{figure}   
\item Consider the game at a traffic light where the equilibrium for both players is a correlated equilibrium where they play the strategy (stop,go) and (go,stop) with equal probabilities. Thus by using no-regret dynamics, it will converge to a correlated equilibrium which is not a mixed Nash.
 \begin{figure}[h]
\renewcommand{\arraystretch}{1.5}
    \centering
    \begin{tabular}{cc|c|c|c|}
      & \multicolumn{1}{c}{} & \multicolumn{2}{c}{P$1$}\\
      & \multicolumn{1}{c}{} & \multicolumn{1}{c}{stop}  & \multicolumn{1}{c}{go} \\\cline{3-4}
      \multirow{2}*{P$2$}  & stop & $0,0$ & $0,1$\\\cline{3-4}
      \cline{3-4}
& go & $1,0$ & $-5,-5$\\      \cline{3-4}
    \end{tabular}
 \end{figure}   

%Consider the cost minimization game below, where for player P1, the weights of $A_1$ and $A_2$ decreases whenever these strategies are played. Thus the weights are concentrated on $A_3$ in the long run and hence the time-averaged history of joint play will correspond to the strategy \{0, 0, 1\}, where $A_3$ is played with probability 1. Similar argument goes for P2 and thus average history of joint play will point to $A_3,B_3$, which is the outcome of the pure strategy \{\{0, 0, 1\}, \{0, 0, 1\}\}


 
% \begin{figure}[h]
%\renewcommand{\arraystretch}{1.5}
%    \centering
%    \begin{tabular}{cc|c|c|c|}
%      & \multicolumn{1}{c}{} & \multicolumn{3}{c}{P$1$}\\
%      & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$A_1$}  & \multicolumn{1}{c}{$A_2$} &\multicolumn{1}{c}{$A_3$}\\\cline{3-5}
%      \multirow{3}*{P$2$}  & $B_1$ & $1,1$ & $1,1$& $0,0$\\\cline{3-5}
%      \cline{3-5}
%& $B_2$ & $1,1$ & $1,1$& $0,0$\\\cline{3-5}
%      & $B_3$ & $0,0$ & $0,0$ &$0,0$\\\cline{3-5}
%    \end{tabular}
% \end{figure}   

 
\end{enumerate}

\section*{Question 3}
For a fixed $t'$ such that $i$ is the smallest integer such that $t'\leq2^i$. Then $\epsilon=\sqrt{\frac{\ln n}{t'}}\geq\sqrt{\frac{\ln n}{2^i}}$ and the regret is at most $2\sqrt{2^i\ln n}$ up till time $t$, i.e.
\begin{align*}
\sum_{t=1}^{t'}\nu^t \leq OPT + 2\sqrt{2^i\ln n}
\end{align*}
Let $kt'\geq T$ for some integer $k$, then
\begin{align*}
\sum_{t=1}^{T}\nu^t \leq\sum_{t=1}^{kt'}\nu^t \leq OPT + k\cdot 2\sqrt{2^i\ln n}=OPT + (2\sqrt{k^2\cdot 2^i\ln n}) \leq OPT + 2\sqrt{k}\sqrt{T\ln n}
\end{align*}
and hence the expected regret is still $O(\sqrt{\ln n/T})$ with respect to every fixed action.

\section*{Question 4}
Let $\label{eq:q4} f_\epsilon(x)=(1-\epsilon)^x$ and $\label{eq:q5}g_\epsilon(x)=1-\epsilon x$, then 
\begin{align*}
&f_\epsilon(0) = 1 = g_\epsilon(0)\\
&f_\epsilon(1) = 1-\epsilon = g_\epsilon(1)\\
&\begin{rcases}
 f'_\epsilon(x)&=(1-\epsilon)^x\ln (1-\epsilon) \\
  g'_\epsilon(x)&=-\epsilon \\
\end{rcases}f'_\epsilon(0) = \ln(1-\epsilon) < -\epsilon= g'_\epsilon(0)
\end{align*}
The last inequality holds since
\begin{align*}
\ln(1-\epsilon)=-\epsilon -\frac{\epsilon^2}{2!(1-\xi)^2}\quad \text{by Taylor's theorem in Lagrange form}
\end{align*}
for some $\xi \in (0,\epsilon)$. Also $f_\epsilon$ is a convex function as $f''_\epsilon(x)=(1-\epsilon)^x\left[\ln (1-\epsilon)\right]^2>0$ for $\epsilon \in(0,1/2]$ on the interval $[0,1]$. This this proves $f_\epsilon(x)\leq g_\epsilon(x)$.

Now let $\hat{f}_\epsilon(x)=(1+\epsilon)^x$, then by Taylor's expansion  %$\hat{g}_\epsilon(x)$ 
\begin{align*}
(1+\epsilon)^x = 1 + \epsilon x + \frac{x(x-1)(1-\xi)^{x-2}}{2!}\epsilon^2
\end{align*}
for some $\xi \in (0,\epsilon)$. We observe that $\frac{x(x-1)(1-\xi)^{x-2}}{2!}\epsilon^2 \leq 0$ since $x \in [0,1]$ we have proved that $(1+\epsilon)^x \leq 1+\epsilon x$.
%Let $f(\epsilon,x)=(1-\epsilon)^x$, then
%\begin{align*}
%\frac{f^{n}(\epsilon,x)}{d\epsilon^n}=(-1)^n\cdot x(x-1)(x-2)\ldots(x-n+1)(1-\epsilon)^{x-n}
%\end{align*}
%Doing Maclaurin series on $f(\epsilon,x)$ for a fixed $x \in [0,1]$ with respect to $\epsilon$, we get:
%\begin{align*}
%(1-\epsilon)^x&=\sum_{n=0}^{\infty}(-1)^n\frac{x(x-1)(x-2)\ldots(x-n+1)}{n!}\epsilon^n\\
%&=1-\epsilon x + \sum_{n=2}^{\infty}(-1)^n\frac{x(x-1)(x-2)\ldots(x-n+1)}{n!}\epsilon^n
%\end{align*}
%To prove the inequality, it suffices to prove that 
%\begin{align*}
%\sum_{n=2}^{\infty}(-1)^n\frac{x(x-1)(x-2)\ldots(x-n+1)}{n!}\epsilon^n \leq 0
%\end{align*}
%which is true since $(-1)^n\cdot x(x-1)(x-2)\ldots(x-n+1) = -x (1-x)(2-x)\ldots (n-1-x)\leq 0$.

\section*{Quetion 5}
Consider the online decision-making setting where every time step $t$ the adversary  chooses a payoff vector $\pi^t:A \to [0,1]$ where the time-averaged regret is defined as $\frac{1}{T} \max_{a\in A}\sum_{t=1}^{T}\pi^t(a)-\frac{1}{T}\sum_{t=1}^{T}\pi^t(a^t)$. Let $\Gamma^t =\sum_{a\in A}w^t(a)$ and define $OPT = \sum_{t=1}^{T}c^t(a^\ast)$ as the cumulative cost for the best fixed action $a^\ast$. Then
\begin{align*}
\Gamma^T&\leq w^T(a^\ast)\\
&=w^1(a^\ast)\prod_{t=1}^{T}(1+\epsilon)^{\pi^t(a^\ast)} = (1+\epsilon)^{OPT}
\end{align*}
Te expectec cost of the MW algorithm at time $t$ is 
\begin{align*}
\sum_{a \in A}p^t(a).\pi^t(a) = \sum_{a \in A}\frac{w^t(a)}{\Gamma^t}\pi^t(a) 
\end{align*}
We can rewrite $\Gamma^{t+1}$ in terms of $\Gamma^t$ in the following manner
\begin{align*}
\Gamma^{t+1} &= \sum_{a \in A}w^{t+1}(a)\\
&= \sum_{a \in A}w^{t}(a)\cdot (1+\epsilon)^{\pi^t(a)}\\
&\leq \sum_{a \in A}w^{t}(a)\cdot (1+\epsilon\pi^t(a)) \quad \text{by Q\ref{eq:q4}}\\
&\leq \Gamma^t\sum_{a \in A}p^{t}(a)\cdot (1+\epsilon\pi^t(a))\\
&\leq \Gamma^t\sum_{a \in A}p^{t}(a)+p^{t}(a)\epsilon\pi^t(a)\\
&\leq \Gamma^t(1+\epsilon\nu^t)\quad \text{where $\nu^t$ is the expected utility at time $t$.}
\end{align*}
Combining the results obtained from before,
\begin{align*}
(1+\epsilon)^{OPT}&\leq \Gamma^T\leq \Gamma^1\prod_{t=1}^{T}(1+\epsilon \nu^t)\\
OPT \ln (1+\epsilon)&\leq  \ln n + \sum_{t=1}^{T}\ln (1+\epsilon \nu^t)\\
OPT (\epsilon-\epsilon^2)\leq OPT \ln (1+\epsilon)&\leq  \ln n + \sum_{t=1}^{T}\ln (1+\epsilon \nu^t)\leq  \ln n + \sum_{t=1}^{T}\epsilon \nu^t\\
OPT (\epsilon-\epsilon^2)&\leq   \ln n + \sum_{t=1}^{T}\epsilon \nu^t\\
OPT &\leq   (\ln n)/\epsilon + \sum_{t=1}^{T}\nu^t +\epsilon \\
OPT &\leq   (\ln n)/\epsilon +\epsilon T + \sum_{t=1}^{T}\nu^t \\
\end{align*}
Hence equalizing the two error terms, we get $\epsilon=\sqrt{\ln n/T}$, similar to the case of the cost vector. Thus it has regret $O(\sqrt{\ln n/T})$

\section*{Question 6}
\begin{enumerate}[(a)]
\item %$(\Rightarrow)$ 
Let $\hat{x}, \hat{y}$ be a mixed Nash equilibrium then,
\begin{align}
\hat{x}^TA\hat{y}&\geq x^TA\hat{y} \quad \text{for all mixed distributions $x$}\\
\hat{x}^TA\hat{y}&\leq \hat{x}^TAy \quad \text{for all mixed distributions $y$}
\end{align}
if and only if,
\begin{align*}
\hat{x}\in\argmax_x \left(x^TA \hat{y}\right)\subseteq\argmax_x\left(\min_yx^TAy\right)\\
\hat{y}\in\argmin_y \left(\hat{x}^T Ay\right)\subseteq\argmin_x\left(\max_xx^TAy\right)
\end{align*}

%$(\Leftarrow)$ 
\item Let $x_1,y_1$ and $x_2,y_2$ be the given mixed Nash equilibria of a two-player zero-sum game. Thus by the above result, for $i=1,2$
\begin{align*}
x_i &\in \argmax_x\left(\min_yx^TAy\right)\\
y_{3-i} & \in\argmin_x\left(\max_xx^TAy\right)
\end{align*}
thus
\begin{align*}
x_i^TAy_{3-i}&\geq x^TAy_{3-i} \quad \text{for all mixed distributions $x$}\\
x_i^TAy_{3-i}&\leq x_i^TAy_{} \quad \text{for all mixed distributions $y$}
\end{align*}
which by definition tells us that $(x_i,y_{3-i})$ is a mixed Nash equilibrium for $i=1,2$.
\end{enumerate}

\section*{Quetion 7}
\begin{enumerate}[(a)]
\item Let $G$ be a general bimatrix game. The mixed strategy of player 1 is a vector $x$ of length $m$. The mixed strategy of player 2 is a vector $y$ of length $n$. The payoff matrices for the two players are $A$ and $B$, each of size $m \times n$. The expected payoff for player 1 is $x\tran Ay$ and the expected payoff for player 2 is $y\tran B\tran x$.

We form a symmetric bimatrix game by concatenating the strategies and the payoff matrices of both players together. 
Let $G'$ be a new bimatrix game formed from $G$ with the following construction:
\begin{itemize}
	\item The payoff matrix for player 1 is
	\begin{align*}
		K = \left[
		\begin{matrix}
		0 & A\\
		B\tran & 0
		\end{matrix}\right]		
	\end{align*}
	and the payoff matrix for player 2 is $K\tran$.
	\item The strategy set of each player is the concatenation of the strategy set of both players (player 1 first). Thus a mixed strategy of each player has the form $z = \left[\begin{matrix}  x \\ y \end{matrix}\right]$, where $x$ and $y$ are constructed from a mixed strategy of players 1 and 2 in $G$ by dividing each coordinate by 2. This is to ensure that $z$ is still a probability distribution.	
\end{itemize}
It follows that $G'$ is a symmetric bimatrix game. Let $(z, z)$ be a symmetric mixed Nash equilibrium of this game. We aim to prove that this equilibrium can be translated back to a mixed Nash equilibrium of the original game by taking the first $m$ coordinates, multiplied by 2, to be the mixed strategy of player 1, and the next $n$ coordinates to be the mixed strategy of player 2. Mathematically, we know that $z$ maximizes the payoffs $z\tran Kz$ of each player; i.e. the optimal expected payoff for each player is
\begin{align*}
	[x\tran \quad y\tran]\left[\begin{matrix}0 & A\\ B\tran & 0\end{matrix}\right]
		\left[\begin{matrix}x\\y\end{matrix}\right] = x\tran A y + y\tran B\tran x
\end{align*}
and we aim to prove that $x$ and $y$ are the mixed Nash strategies of the original game.
%maximizes $x\tran A y$ and $y\tran B\tran x$ simultaneously as well.

\begin{proof}
	Let $i$ be a coordinate such that $x_i > 0$. Because $z$ is an MNE, strategy $i$ must have the highest expected payoff for player 1
	\begin{align*}
		(Kz)_i \geq (Kz)_j \quad \forall j
	\end{align*}
	but
	\begin{align*}
		Kz= \left[	\begin{matrix}
			0 & A\\
			B\tran & 0
		\end{matrix}\right]	\left[\begin{matrix}x\\y\end{matrix}\right] =	
		\left[\begin{matrix}
			Ay \\ B\tran x
		\end{matrix}\right]
	\end{align*}	
	So the $i^\text{th}$ entry that is the largest in $Kz$ is also the largest in $Ay$. This implies that $x$ is the mixed Nash strategy for player 1 in the original game. With similar argument, we also conclude that $y$ is the mixed Nash strategy for player 2. Thus $(x, y)$ is an MNE of the original game.
\end{proof}

Note: if we concatenate the payoff matrices in this way
\begin{align*}
	K = \left[
	\begin{matrix}
	A & 0\\
	0 & B\tran
	\end{matrix}\right]		
\end{align*}
then the new strategy of player 1 is $\left[\begin{matrix}  x \\ y \end{matrix}\right]$ and the strategy of player 2 is $\left[\begin{matrix}  y \\ x \end{matrix}\right]$. This cannot lead to a symmetric Nash equilibrium of the form $\left(\left[\begin{matrix}  x \\ y \end{matrix}\right], \left[\begin{matrix}  x \\ y \end{matrix}\right]\right)$ which is desirable. Therefore, we adjust this a bit to have the appropriate form mentioned above.

\item We aim to prove that if $(z^1, z^2)$ is an MNE of $G'$ then $(z^1, z^1)$ is also an MNE. Or we can somehow use the result from question 6 where if (x1, y1) and (x2, y2) are both MNE then so are (x1, y2) and (x2, y1).


\end{enumerate}


\end{document}