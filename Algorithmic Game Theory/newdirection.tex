\documentclass[a4paper,10pt]{article}
\setlength{\parindent}{0cm}
\usepackage{amsmath, amssymb, amsthm, mathtools,pgfplots}
\usepackage{graphicx,caption}
\usepackage{verbatim}
\usepackage{venndiagram}
\usepackage[cm]{fullpage}
\usepackage{fancyhdr}
\usepackage{tikz}
\usepackage{listings,url,}
\usepackage{color,enumerate,framed}
\usepackage{color,hyperref}
\definecolor{darkblue}{rgb}{0.0,0.0,0.5}
\hypersetup{colorlinks,breaklinks,
            linkcolor=darkblue,urlcolor=darkblue,
            anchorcolor=darkblue,citecolor=darkblue}
\usetikzlibrary{arrows,positioning} 
\usepackage{sectsty}
%\allsectionsfont{\centering}
%\usepackage[normalem]{ulem}
%\allsectionsfont{\sffamily}
%\sectionfont{\centering\ulemheading{\uuline}}

%\usepackage{tgadventor}
%\usepackage[nohug]{diagrams}
\usepackage[T1]{fontenc}
%\usepackage{helvet}
%\renewcommand{\familydefault}{\sfdefault}
\usepackage{parskip}
%\usepackage{picins} %for \parpic.
%\newtheorem*{notation}{Notation}
%\newtheorem{example}{Example}[section]
%\newtheorem*{problem}{Problem}
\theoremstyle{definition}
%\newtheorem{theorem}{Theorem}
%\newtheorem*{solution}{Solution}
%\newtheorem*{definition}{Definition}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem*{remark}{Remark}
%\setcounter{section}{1}

\newtheorem{thm}{Theorem}[section]
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{defn}[thm]{Definition}
\newtheorem*{examp}{Example}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{rmk}[thm]{Remark}
\newtheorem*{nte}{Note}
\newtheorem*{notat}{Notation}

%\diagramstyle[labelstyle=\scriptstyle]

\lstset{frame=tb,
  language=Oz,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}


\pagestyle{fancy}




\fancyhead{}
\renewcommand{\headrulewidth}{0pt}

\lfoot{\color{black!60}{\sffamily Zhangsheng}}
\cfoot{}
\cfoot{\color{black!60}{\sffamily Last modified: \today}}
\rfoot{\color{black!60}{\sffamily\thepage}}



\begin{document}
\begin{flushright}
Zhangsheng Lai
\end{flushright}

\section*{A new direction}
We noticed that in most of the models that we read (cf.  \cite{Drago1991}, \cite{Chakravarti2015}), the workplace reward maximizing game that was played is static and there are no dynamics involved. However, in real scenarios, when someone joins a new company, the newcomer does not immediately decide to purely cooperate or compete, similiarly, this is true his new colleagues too. After some interaction with each other over a time span, everyone will have a rough idea of everybody's work style and ethnics. This will then allow the agent to decide whether to cooperate or compete with each agent respectively which we shall call it the nature of the agent. Such a model would be a more realistic scenario as it gives each agent time to learn about the environment before determining his nature. 

\begin{defn}
The \emph{nature} of an agent in a workplace reward maximizing game with $k$ agents is a vector $\mathbf{x_i}=(x^i_1,x^i_2,\ldots, x^i_k)$ such that $\sum x_i=1$. It is a discrete probability distribution where $x^i_j$ denotes the probability of cooperating with agent $j$ and $x^i_i$ denotes the probability of not cooperating. \label{def:nature}
\end{defn}

With the definition \ref{def:nature} we see that a \emph{completely cooperative} agent $i$ is one with $x^i_i=0$ and a \emph{completely competitive} agent has $x^i_i=1$. A game where all the agents are completely cooperative is called a \emph{completely cooperative environment} and if all the agents are completely competitive, it is a \emph{completely competitive environment}.

We would now like to introduce some form of dynamics in which the players learn whether it is to their benefit to cooperate or compete with a given agent. Here we will approach it in a similar fashion of \emph{no-regret dynamics} where we want to minimize regret in single decision-maker playing game against an adversary. In our setting the adversary is the other $k-1$ agents and its ability to extend it to multi-player games and relation to coarse correlated equilibria is how we plan to model our game. (We would then vary the different reward systems to see how it will cause the CCE to change and whether we can design a reward system with the dominant-strategy incentive-compatible (DSIC) for workplace reward maximizing games.)

\subsection*{The model} 
Let $A$ be a set of actions playable by the agent in the workplace reward maximizing game with $|A|\geq 2$. At time $t=1,2,\ldots, T$
\begin{enumerate}[(i)]
\item The agent plays a mixed strategy $p^t$, which is a probability distribution over $A$.
\item The adversary picks a cost vector $c^t: A \to [0,1]$
\end{enumerate}

(The other $k-1$ agents models the adversary well as what the agent plays can b)


























































\bibliography{AGT_project} 
\bibliographystyle{apalike}
\end{document}