Automatically generated by Mendeley Desktop 1.17.13
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Bottou2011,
abstract = {A plausible definition of "reasoning" could be "algebraically manipulating previously acquired knowledge in order to answer a new question". This definition covers first-order logical inference or probabilistic inference. It also includes much simpler manipulations commonly used to build large learning systems. For instance, we can build an optical character recognition system by first training a character segmenter, an isolated character recognizer, and a language model, using appropriate labeled training sets. Adequately concatenating these modules and fine tuning the resulting system can be viewed as an algebraic operation in a space of models. The resulting model answers a new question, that is, converting the image of a text page into a computer readable text. This observation suggests a conceptual continuity between algebraically rich inference systems, such as logical or probabilistic inference, and simple manipulations, such as the mere concatenation of trainable learning systems. Therefore, instead of trying to bridge the gap between machine learning systems and sophisticated "all-purpose" inference mechanisms, we can instead algebraically enrich the set of manipulations applicable to training systems, and build reasoning capabilities from the ground up.},
archivePrefix = {arXiv},
arxivId = {1102.1808},
author = {Bottou, Leon},
doi = {10.1007/s10994-013-5335-x},
eprint = {1102.1808},
file = {:C$\backslash$:/Users/zlai/Desktop/PDFs/papers/1102.1808.pdf:pdf},
isbn = {0885-6125},
issn = {0885-6125},
journal = {Arxiv preprint arXiv11021808},
pages = {15},
title = {{From Machine Learning to Machine Reasoning}},
url = {http://arxiv.org/abs/1102.1808},
year = {2011}
}

@article{Santoro2017,
abstract = {Relational reasoning is a central component of generally intelligent behavior, but has proven difficult for neural networks to learn. In this paper we describe how to use Relation Networks (RNs) as a simple plug-and-play module to solve problems that fundamentally hinge on relational reasoning. We tested RN-augmented networks on three tasks: visual question answering using a challenging dataset called CLEVR, on which we achieve state-of-the-art, super-human performance; text-based question answering using the bAbI suite of tasks; and complex reasoning about dynamic physical systems. Then, using a curated dataset called Sort-of-CLEVR we show that powerful convolutional networks do not have a general capacity to solve relational questions, but can gain this capacity when augmented with RNs. Our work shows how a deep learning architecture equipped with an RN module can implicitly discover and learn to reason about entities and their relations.},
archivePrefix = {arXiv},
arxivId = {1706.01427},
author = {Santoro, Adam and Raposo, David and Barrett, David G. T. and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Timothy},
doi = {10.1109/WACV.2017.108},
eprint = {1706.01427},
file = {:C$\backslash$:/Users/zlai/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Santoro et al. - 2017 - A simple neural network module for relational reasoning.pdf:pdf},
isbn = {9781509048229},
issn = {21607516},
pages = {1--16},
title = {{A simple neural network module for relational reasoning}},
url = {http://arxiv.org/abs/1706.01427},
year = {2017}
}

@article{Mascharka2018,
abstract = {Visual question answering requires high-order reasoning about an image, which is a fundamental capability needed by machine systems to follow complex directives. Recently, modular networks have been shown to be an effective framework for performing visual reasoning tasks. While modular networks were initially designed with a degree of model transparency, their performance on complex visual reasoning benchmarks was lacking. Current state-of-the-art approaches do not provide an effective mechanism for understanding the reasoning process. In this paper, we close the performance gap between interpretable models and state-of-the-art visual reasoning methods. We propose a set of visual-reasoning primitives which, when composed, manifest as a model capable of performing complex reasoning tasks in an explicitly-interpretable manner. The fidelity and interpretability of the primitives' outputs enable an unparalleled ability to diagnose the strengths and weaknesses of the resulting model. Critically, we show that these primitives are highly performant, achieving state-of-the-art accuracy of 99.1{\%} on the CLEVR dataset. We also show that our model is able to effectively learn generalized representations when provided a small amount of data containing novel object attributes. Using the CoGenT generalization task, we show more than a 20 percentage point improvement over the current state of the art.},
archivePrefix = {arXiv},
arxivId = {1803.05268},
author = {Mascharka, David and Tran, Philip and Soklaski, Ryan and Majumdar, Arjun},
doi = {10.1109/CVPR.2018.00519},
eprint = {1803.05268},
file = {:C$\backslash$:/Users/zlai/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mascharka et al. - 2018 - Transparency by Design Closing the Gap Between Performance and Interpretability in Visual Reasoning.pdf:pdf},
title = {{Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning}},
url = {http://arxiv.org/abs/1803.05268},
year = {2018}
}

@article{Weston2015,
abstract = {One long-term goal of machine learning research is to produce methods that are applicable to reasoning and natural language, in particular building an intelligent dialogue agent. To measure progress towards that goal, we argue for the usefulness of a set of proxy tasks that evaluate reading comprehension via question answering. Our tasks measure understanding in several ways: whether a system is able to answer questions via chaining facts, simple induction, deduction and many more. The tasks are designed to be prerequisites for any system that aims to be capable of conversing with a human. We believe many existing learning systems can currently not solve them, and hence our aim is to classify these tasks into skill sets, so that researchers can identify (and then rectify) the failings of their systems. We also extend and improve the recently introduced Memory Networks model, and show it is able to solve some, but not all, of the tasks.},
archivePrefix = {arXiv},
arxivId = {1502.05698},
author = {Weston, Jason and Bordes, Antoine and Chopra, Sumit and Rush, Alexander M. and van Merri{\"{e}}nboer, Bart and Joulin, Armand and Mikolov, Tomas},
doi = {10.1016/j.jpowsour.2014.09.131},
eprint = {1502.05698},
file = {:C$\backslash$:/Users/zlai/Desktop/PDFs/papers/1502.05698.pdf:pdf},
isbn = {1502.05698},
issn = {03787753},
title = {{Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks}},
url = {http://arxiv.org/abs/1502.05698},
year = {2015}
}

@article{Cer2018,
abstract = {We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.},
archivePrefix = {arXiv},
arxivId = {1803.11175},
author = {Cer, Daniel and Yang, Yinfei and Kong, Sheng-yi and Hua, Nan and Limtiaco, Nicole and John, Rhomni St. and Constant, Noah and Guajardo-Cespedes, Mario and Yuan, Steve and Tar, Chris and Sung, Yun-Hsuan and Strope, Brian and Kurzweil, Ray},
doi = {10.1007/s11423-014-9358-1},
eprint = {1803.11175},
file = {:C$\backslash$:/Users/zlai/Desktop/PDFs/papers/1803.11175.pdf:pdf},
issn = {1042-1629},
title = {{Universal Sentence Encoder}},
url = {http://arxiv.org/abs/1803.11175},
year = {2018}
}

@article{Johnson2017,
abstract = {Existing methods for visual reasoning attempt to directly map inputs to outputs using black-box architectures without explicitly modeling the underlying reasoning processes. As a result, these black-box models often learn to exploit biases in the data rather than learning to perform visual reasoning. Inspired by module networks, this paper proposes a model for visual reasoning that consists of a program generator that constructs an explicit representation of the reasoning process to be performed, and an execution engine that executes the resulting program to produce an answer. Both the program generator and the execution engine are implemented by neural networks, and are trained using a combination of backpropagation and REINFORCE. Using the CLEVR benchmark for visual reasoning, we show that our model significantly outperforms strong baselines and generalizes better in a variety of settings.},
archivePrefix = {arXiv},
arxivId = {1705.03633},
author = {Johnson, Justin and Hariharan, Bharath and Maaten, Laurens Van Der and Hoffman, Judy and Fei-Fei, Li and Zitnick, C. Lawrence and Girshick, Ross},
doi = {10.1109/ICCV.2017.325},
eprint = {1705.03633},
file = {:C$\backslash$:/Users/zlai/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Johnson et al. - 2017 - Inferring and Executing Programs for Visual Reasoning.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {3008--3017},
title = {{Inferring and Executing Programs for Visual Reasoning}},
volume = {2017-Octob},
year = {2017}
}
@article{Sukhbaatar2015,
abstract = {We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network (Weston et al., 2015) but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.},
archivePrefix = {arXiv},
arxivId = {1503.08895},
author = {Sukhbaatar, Sainbayar and Szlam, Arthur and Weston, Jason and Fergus, Rob},
doi = {v5},
eprint = {1503.08895},
file = {:C$\backslash$:/Users/zlai/Desktop/PDFs/papers/1503.08895.pdf:pdf},
isbn = {1551-6709},
issn = {10495258},
pages = {1--11},
pmid = {9377276},
title = {{End-To-End Memory Networks}},
url = {http://arxiv.org/abs/1503.08895},
year = {2015}
}


@article{Weston2015a,
abstract = {We describe a new class of learning models called memory networks. Memory networks reason with inference components combined with a long-term memory component; they learn how to use these jointly. The long-term memory can be read and written to, with the goal of using it for prediction. We investigate these models in the context of question answering (QA) where the long-term memory effectively acts as a (dynamic) knowledge base, and the output is a textual response. We evaluate them on a large-scale QA task, and a smaller, but more complex, toy task generated from a simulated world. In the latter, we show the reasoning power of such models by chaining multiple supporting sentences to answer questions that require understanding the intension of verbs.},
archivePrefix = {arXiv},
arxivId = {arXiv:1410.3916v11},
author = {Weston, Jason and Chopra, Sumit and Bordes, Antoine},
doi = {v0},
eprint = {arXiv:1410.3916v11},
file = {:C$\backslash$:/Users/zlai/Desktop/PDFs/papers/1410.3916.pdf:pdf},
isbn = {9781424469178},
issn = {1098-7576},
pages = {1--15},
pmid = {9377276},
title = {{Memory Networks}},
url = {https://arxiv.org/pdf/1410.3916.pdf},
year = {2015}
}
