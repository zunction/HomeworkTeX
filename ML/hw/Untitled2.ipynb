{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages for homework task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "import keras\n",
    "from keras import callbacks\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change to the directory containing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/zlai/Documents/repo/HomeworkTex/ML/hw/homework 1/data/train/airplane\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** The inputs are feature vectors that describe the images and the output is the correct label of the image class from the set $\\{\\mathsf{airplane}, \\mathsf{automobile}, \\mathsf{bird}, \\mathsf{cat}\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the image image into a feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using the raw pixel values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each `.jpg` image, we can extract the raw pixel values using `cv2.imread` which returns an array representing the raw RGB intensities of the image. Using `.flatten()` we convert the raw image from a multi-dimensional array into a single array of values with dimensions `(3072,)`, which can be used as the input for the classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_img = cv2.imread('1.jpg')\n",
    "print (raw_img.shape)\n",
    "plt.imshow(raw_img)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2pixel_value(filename):\n",
    "    \"\"\"\n",
    "    Converts the filename into a flatten numpy array of the raw pixel values.\n",
    "    Input:\n",
    "    - filename (string): name of the file to be processed.\n",
    "    \"\"\"\n",
    "    raw_img = cv2.imread(filename)\n",
    "    \n",
    "    return raw_img.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072,)\n"
     ]
    }
   ],
   "source": [
    "out = convert2pixel_value('1.jpg')\n",
    "print (out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using the mean and standard deviation of each color channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From each raw image, we can extract out the color channels (RGB), and find the mean and standard deviation value of each color. This array can be used as the feature vector for the classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2color_mean_std(filename):\n",
    "    \"\"\"\n",
    "    Converts the filename into the mean and standard deviation of the different color channels (RGB).\n",
    "    Input:\n",
    "    - filename (string): name of the file to be processed.\n",
    "    \"\"\"\n",
    "    raw_img = cv2.imread(filename)\n",
    "        \n",
    "    return cv2.meanStdDev(raw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mean,std) = convert2color_mean_std('1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148.86035156]\n",
      " [148.71875   ]\n",
      " [148.17578125]]\n",
      "[[90.06941242]\n",
      " [92.22082554]\n",
      " [91.80958747]]\n"
     ]
    }
   ],
   "source": [
    "print (mean)\n",
    "print (std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using a color histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a raw image, we can also extract the color histogram of the image. Depending on the number of bins chosen for the histogram, it will decide the dimension of this feature vector. For example, if we choose 8 bins for each histogram, this means that the values for each color channel will be classified into the following ranges: 0-31, 32-63, 64-95, 96-127, 128-159, 160-191, 192-223, 224-256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2color_hist(filename, bin):\n",
    "    \"\"\"\n",
    "    Converts the filename into a histogram with bin bins for each of the different color channels (RGB). The concatenated \n",
    "    vector of the different color histogram is returned.\n",
    "    Input:\n",
    "    - filename (string): name of the file to be processed.\n",
    "    - bin: number of bins for the histogram of each color channel.\n",
    "    \"\"\"\n",
    "    raw_img = cv2.imread(filename)\n",
    "    hist = []\n",
    "    color = ('b','g','r')\n",
    "    for channel,col in enumerate(color):\n",
    "        histr = cv2.calcHist([raw_img],[channel],None,[bin],[0,256])\n",
    "        hist.append(histr)\n",
    "    return np.concatenate(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 1)\n"
     ]
    }
   ],
   "source": [
    "output = convert2color_hist('1.jpg',bin=8)\n",
    "print (output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a 3D histogram as the feature vector. Depending on the choice of the number of bins, `b`, we will get a multi-dimensional array of shape `(b,b,b)`. This describes the number of pixels that have blue, green and red in the different intervals corresponding to the number of bins selected. To use it as a feature vector, we simply flatten it to get a vector of dimension `b**3`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2color_3Dhist(filename, bin = 8):\n",
    "    \"\"\"\n",
    "    Converts the filename into a 3D histogram. The 3D histogram values are then flattened to return a single dimension array.\n",
    "    Input:\n",
    "    - filename (string): name of the file to be processed.\n",
    "    - bin: number of bins for the histogram of each color channel.\n",
    "    \"\"\"\n",
    "    raw_img = cv2.imread(filename)\n",
    "    histr = cv2.calcHist([raw_img],[0,1,2],None,[bin]*3,[0,256]*3)\n",
    "        \n",
    "    return histr.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "output = convert2color_3Dhist('1.jpg')\n",
    "print (output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Q2.** Logistic regression algorithm using stochastic gradient descent to perform binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Loads data into pixel values from the list of path given. Returns \n",
    "    Input:\n",
    "    - path (list): list of path to load the data from.\n",
    "    \"\"\"\n",
    "    x_train=[]\n",
    "    y_train=[]\n",
    "    for c,i in enumerate(path):\n",
    "        os.chdir(i)\n",
    "        l = os.listdir()\n",
    "        for i in l:\n",
    "            raw_img = convert2pixel_value(i)\n",
    "            x_train.append(raw_img)\n",
    "            y_train.append(c)\n",
    "    \n",
    "    x_train = np.concatenate([i[np.newaxis] for i in x_train])\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    # comment below to remove the shuffling of the data\n",
    "    arr = np.arange(x_train.shape[0])\n",
    "    np.random.shuffle(arr)\n",
    "    x_train = x_train[arr]\n",
    "    y_train = y_train[arr]\n",
    "    \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the path to the directories containing the images then load the data set using `load_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bird = \"C:/Users/zlai/Documents/repo/HomeworkTex/ML/hw/homework 1/data/train/bird\"\n",
    "train_cat = \"C:/Users/zlai/Documents/repo/HomeworkTex/ML/hw/homework 1/data/train/cat\"\n",
    "test_bird = \"C:/Users/zlai/Documents/repo/HomeworkTex/ML/hw/homework 1/data/test/bird\"\n",
    "test_cat = \"C:/Users/zlai/Documents/repo/HomeworkTex/ML/hw/homework 1/data/test/cat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from `bird` and `cat` folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_data([train_cat, train_bird])\n",
    "x_test, y_test = load_data([test_cat, test_bird])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 3072)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do some preprocessing of the training data by normalizing the pixel values to between $[0,1]$ and the labels to be $\\{-1,+1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "y_train = y_train*2 - 1\n",
    "y_test = y_test*2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 training samples\n",
      "40 test samples\n"
     ]
    }
   ],
   "source": [
    "print (x_train.shape[0], 'training samples')\n",
    "print (x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize parameters for the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072,)\n",
      "(40, 3072)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.normal(size=(3072,))\n",
    "print(W.shape)\n",
    "print (x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Applies the sigmoid function on the given vector.\n",
    "    Input(s):\n",
    "    - x : numpy vector of values\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params(seed=123):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    return rng.normal(size=(3072,))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(x_train, y_train, W):\n",
    "    \"\"\"\n",
    "    Computes the loss value of the logistic loss.\n",
    "    Input(s):\n",
    "    - \n",
    "    \"\"\"\n",
    "    z = y_train * np.dot(x_train, W)\n",
    "    h = sigmoid(z)\n",
    "    \n",
    "    return -np.mean(np.log(h))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_grad(x_train, y_train, W):\n",
    "    \"\"\"\n",
    "    Computes the gradient of the logistic loss function.\n",
    "    Input(s):\n",
    "    - \n",
    "    \"\"\"\n",
    "    z = y_train * np.dot(x_train, W)\n",
    "    h = sigmoid(z)\n",
    "    \n",
    "    return np.dot(x_train.T,(y_train * (1-h)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(x_train, y_train, batch_size=2):\n",
    "    \"\"\"\n",
    "    Returns a batch of size batch_size for stochastic gradient descent.\n",
    "    \"\"\"\n",
    "    for i in np.arange(0, x_train.shape[0], batch_size):\n",
    "        yield (x_train[i:i+batch_size],y_train[i:i+batch_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_train(x_train, y_train, W, alpha=0.001, batch_size = 2, epoch = 10):\n",
    "    \"\"\"\n",
    "    Training\n",
    "    \"\"\"\n",
    "    for e in np.arange(epoch):\n",
    "        epoch_loss = []\n",
    "        for (batchx, batchy) in next_batch(x_train, y_train):\n",
    "            loss = log_loss(batchx, batchy, W)\n",
    "            grad = log_grad(batchx, batchy, W)\n",
    "            epoch_loss.append(loss)\n",
    "            W += -alpha * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072,)\n"
     ]
    }
   ],
   "source": [
    "W = initialize_params()\n",
    "print (W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 3072)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40,)\n",
      "(40,)\n"
     ]
    }
   ],
   "source": [
    "z = y_train * np.dot(x_train, W)\n",
    "h = sigmoid(z)\n",
    "print (z.shape)\n",
    "print (h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x_train.T,(y_train * (1-h))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1 -1 -1 -1  1  1 -1  1  1 -1 -1  1 -1 -1  1 -1  1 -1  1  1 -1\n",
      " -1 -1 -1 -1 -1  1  1 -1  1  1 -1 -1  1  1  1 -1]\n",
      "[27.64886838 77.07725064 76.40734938 66.43585408 65.66377491 79.08050574\n",
      " 47.65292059 63.02409751 75.49298293 45.85660047 70.80784421 77.28824942\n",
      " 45.13578479 41.24251855 27.25329804 59.30722835 44.31571494 58.74910697\n",
      " 62.17372771 50.91266804 51.880467   24.68281353 76.01787984 43.12813924\n",
      " 58.81991592 55.30029501 13.48201072 46.97249908 57.47911648 47.46808431\n",
      " 32.39376958 39.82011415 58.44696985 43.44037813 31.11623659 75.16045279\n",
      " 68.25619595 28.69121687 41.04921203 54.51582545]\n"
     ]
    }
   ],
   "source": [
    "print (y_train)\n",
    "print (np.dot(x_train,W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1018.1038498607807"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.log(sigmoid(y_train *np.dot(x_train,W))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19215686, 0.25490196, 0.25098039, ..., 0.40784314, 0.45098039,\n",
       "       0.46666667])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "c = np.array([0,1,2])\n",
    "print (c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
