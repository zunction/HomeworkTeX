{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages for homework task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "import keras\n",
    "from keras import callbacks\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change to the directory containing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/zlai/Documents/repo/HomeworkTex/ML/hw/homework 1/data/train/airplane\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** The inputs are feature vectors that describe the images and the output is the correct label of the image class from the set $\\{\\mathsf{airplane}, \\mathsf{automobile}, \\mathsf{bird}, \\mathsf{cat}\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the image image into a feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using the raw pixel values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each `.jpg` image, we can extract the raw pixel values using `cv2.imread` which returns an array representing the raw RGB intensities of the image. Using `.flatten()` we convert the raw image from a multi-dimensional array into a single array of values with dimensions `(3072,)`, which can be used as the input for the classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_img = cv2.imread('1.jpg')\n",
    "print (raw_img.shape)\n",
    "plt.imshow(raw_img)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2pixel_value(filename):\n",
    "    \"\"\"\n",
    "    Converts the filename into a flatten numpy array of the raw pixel values.\n",
    "    Input:\n",
    "    - filename (string): name of the file to be processed.\n",
    "    \"\"\"\n",
    "    raw_img = cv2.imread(filename)\n",
    "    \n",
    "    return raw_img.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072,)\n"
     ]
    }
   ],
   "source": [
    "out = convert2pixel_value('1.jpg')\n",
    "print (out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using the mean and standard deviation of each color channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From each raw image, we can extract out the color channels (RGB), and find the mean and standard deviation value of each color. This array can be used as the feature vector for the classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2color_mean_std(filename):\n",
    "    \"\"\"\n",
    "    Converts the filename into the mean and standard deviation of the different color channels (RGB).\n",
    "    Input:\n",
    "    - filename (string): name of the file to be processed.\n",
    "    \"\"\"\n",
    "    raw_img = cv2.imread(filename)\n",
    "        \n",
    "    return cv2.meanStdDev(raw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mean,std) = convert2color_mean_std('1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148.86035156]\n",
      " [148.71875   ]\n",
      " [148.17578125]]\n",
      "[[90.06941242]\n",
      " [92.22082554]\n",
      " [91.80958747]]\n"
     ]
    }
   ],
   "source": [
    "print (mean)\n",
    "print (std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using a color histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a raw image, we can also extract the color histogram of the image. Depending on the number of bins chosen for the histogram, it will decide the dimension of this feature vector. For example, if we choose 8 bins for each histogram, this means that the values for each color channel will be classified into the following ranges: 0-31, 32-63, 64-95, 96-127, 128-159, 160-191, 192-223, 224-256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2color_hist(filename, bin):\n",
    "    \"\"\"\n",
    "    Converts the filename into a histogram with bin bins for each of the different color channels (RGB). The concatenated \n",
    "    vector of the different color histogram is returned.\n",
    "    Input:\n",
    "    - filename (string): name of the file to be processed.\n",
    "    - bin: number of bins for the histogram of each color channel.\n",
    "    \"\"\"\n",
    "    raw_img = cv2.imread(filename)\n",
    "    hist = []\n",
    "    color = ('b','g','r')\n",
    "    for channel,col in enumerate(color):\n",
    "        histr = cv2.calcHist([raw_img],[channel],None,[bin],[0,256])\n",
    "        hist.append(histr)\n",
    "    return np.concatenate(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 1)\n"
     ]
    }
   ],
   "source": [
    "output = convert2color_hist('1.jpg',bin=8)\n",
    "print (output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a 3D histogram as the feature vector. Depending on the choice of the number of bins, `b`, we will get a multi-dimensional array of shape `(b,b,b)`. This describes the number of pixels that have blue, green and red in the different intervals corresponding to the number of bins selected. To use it as a feature vector, we simply flatten it to get a vector of dimension `b**3`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2color_3Dhist(filename, bin = 8):\n",
    "    \"\"\"\n",
    "    Converts the filename into a 3D histogram. The 3D histogram values are then flattened to return a single dimension array.\n",
    "    Input:\n",
    "    - filename (string): name of the file to be processed.\n",
    "    - bin: number of bins for the histogram of each color channel.\n",
    "    \"\"\"\n",
    "    raw_img = cv2.imread(filename)\n",
    "    histr = cv2.calcHist([raw_img],[0,1,2],None,[bin]*3,[0,256]*3)\n",
    "        \n",
    "    return histr.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "output = convert2color_3Dhist('1.jpg')\n",
    "print (output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Q2.** Logistic regression algorithm using stochastic gradient descent to perform binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Loads data into pixel values from the list of path given. Returns \n",
    "    Input:\n",
    "    - path (list): list of path to load the data from.\n",
    "    \"\"\"\n",
    "    x_train=[]\n",
    "    y_train=[]\n",
    "    for c,i in enumerate(path):\n",
    "        os.chdir(i)\n",
    "        l = os.listdir()\n",
    "        for i in l:\n",
    "            raw_img = convert2pixel_value(i)\n",
    "            x_train.append(raw_img)\n",
    "            y_train.append(c)\n",
    "    \n",
    "    x_train = np.concatenate([i[np.newaxis] for i in x_train])\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    # comment below to remove the shuffling of the data\n",
    "    arr = np.arange(40)\n",
    "    np.random.shuffle(arr)\n",
    "    x_train = x_train[arr]\n",
    "    y_train = y_train[arr]\n",
    "    \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the path to the directories containing the images then load the data set using `load_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bird = \"C:/Users/zlai/Documents/repo/HomeworkTex/ML/hw/homework 1/data/train/bird\"\n",
    "train_cat = \"C:/Users/zlai/Documents/repo/HomeworkTex/ML/hw/homework 1/data/train/cat\"\n",
    "test_bird = \"C:/Users/zlai/Documents/repo/HomeworkTex/ML/hw/homework 1/data/test/bird\"\n",
    "test_cat = \"C:/Users/zlai/Documents/repo/HomeworkTex/ML/hw/homework 1/data/test/cat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from `bird` and `cat` folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_data([train_cat, train_bird])\n",
    "x_test, y_test = load_data([test_cat, test_bird])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 3072)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do some preprocessing of the training data by normalizing the pixel values to between $[0,1]$ and the labels to be $\\{-1,+1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "y_train = y_train*2 - 1\n",
    "y_test = y_test*2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 training samples\n",
      "40 test samples\n"
     ]
    }
   ],
   "source": [
    "print (x_train.shape[0], 'training samples')\n",
    "print (x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize parameters for the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.normal(size=(3072,))\n",
    "print(W.shape)\n",
    "print (x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Applies the sigmoid function on the given vector.\n",
    "    Input(s):\n",
    "    - x : numpy vector of values\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params(seed=123):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    return rng.normal(size=(3072,))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(x_train, y_train, seed = 123):\n",
    "    \"\"\"\n",
    "    Computes the loss value of the logistic loss.\n",
    "    Input(s):\n",
    "    - \n",
    "    \"\"\"\n",
    "    W = initialize_params()\n",
    "    z = y_train * np.dot(x_train, W)\n",
    "    h = sigmoid(z)\n",
    "    \n",
    "    return np.sum(np.log(h))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-284.4691823206594"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_grad(x_train, y_train, W):\n",
    "    \"\"\"\n",
    "    Computes the gradient of the logistic loss function.\n",
    "    Input(s):\n",
    "    - \n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (y_train)\n",
    "print (np.dot(x_train,W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.log(sigmoid(y_train *np.dot(x_train,W))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([0,1,2])\n",
    "print (c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = Input(shape=(3072,))\n",
    "out = keras.layers.Dense(2, activation='sigmoid')(data_input)\n",
    "model = keras.models.Model(inputs=[data_input], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoints = callbacks.ModelCheckpoint(\"weights_{epoch:02d}_{val_loss:.2f}.h5\", monitor='val_loss',\n",
    "                                                    verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 5\n",
    "model_log = model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size, # number of samples to be used for each gradient update\n",
    "                      epochs=epochs, # number of iterations over the entire x_train data\n",
    "                      validation_data=(x_test, y_test), # on which to evaluate loss and model metrics at the end of each epoch\n",
    "                      callbacks=[model_checkpoints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
