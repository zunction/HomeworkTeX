\documentclass[a4paper,10pt]{article}
%\setlength{\parindent}{0cm}
\usepackage{amsmath, amssymb, amsthm, mathtools,pgfplots}
\usepackage{graphicx,caption}
\usepackage{verbatim}
\usepackage{venndiagram}
%\usepackage[cm]{fullpage}
\usepackage{fullpage}
\usepackage{fancyhdr}
\usepackage{tikz}
\usepackage{listings}
\usepackage{color,enumerate,framed}
\usepackage{color,hyperref}
\definecolor{darkblue}{rgb}{0.0,0.0,0.5}
\hypersetup{colorlinks,breaklinks,
            linkcolor=darkblue,urlcolor=darkblue,
            anchorcolor=darkblue,citecolor=darkblue}
\usepackage[utf8]{inputenc}

% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{10} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{10}  % for normal

% Custom colors
\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

\usepackage{listings}

% Python style for highlighting
\newcommand\pythonstyle{\lstset{
language=Python,
basicstyle=\ttm,
otherkeywords={self},             % Add keywords here
keywordstyle=\ttb\color{deepblue},
emph={MyClass,__init__},          % Custom highlighting
emphstyle=\ttb\color{deepred},    % Custom highlighting style
stringstyle=\color{deepgreen},
frame=tb,                         % Any extra options here
showstringspaces=false            % 
}}

%\setlength{\parskip}{1em}

% Python environment
\lstnewenvironment{python}[1][]
{
\pythonstyle
\lstset{#1}
}
{}

% Python for external files
\newcommand\pythonexternal[2][]{{
\pythonstyle
\lstinputlisting[#1]{#2}}}

\usepackage{sectsty}
%\allsectionsfont{\centering}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}
%\usepackage{tgadventor}
%\usepackage[nohug]{diagrams}
\usepackage[T1]{fontenc}
%\usepackage{helvet}
%\renewcommand{\familydefault}{\sfdefault}
%\usepackage{parskip}
%\usepackage{picins} %for \parpic.
%\newtheorem*{notation}{Notation}
%\newtheorem{example}{Example}[section]
%\newtheorem*{problem}{Problem}
\theoremstyle{definition}
%\newtheorem{theorem}{Theorem}
%\newtheorem*{solution}{Solution}
%\newtheorem*{definition}{Definition}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem*{remark}{Remark}
%\setcounter{section}{1}

\newtheorem{thm}{Theorem}[section]
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{defn}[thm]{Definition}
\newtheorem*{examp}{Example}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{rmk}[thm]{Remark}
\newtheorem*{nte}{Note}
\newtheorem*{notat}{Notation}

%\diagramstyle[labelstyle=\scriptstyle]

\lstset{frame=tb,
  language=Oz,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\pagestyle{fancy}

\numberwithin{equation}{section}

\usepackage[utf8]{inputenc}

\newcommand\xqed[1]{%
  \leavevmode\unskip\penalty9999 \hbox{}\nobreak\hfill
  \quad\hbox{#1}}
\newcommand\eqed{\xqed{$\blacktriangle$}}

\fancyhead{}
\renewcommand{\headrulewidth}{0pt}

\lfoot{\color{black!60}{\sffamily Zhangsheng Lai}}
\cfoot{\color{black!60}{\sffamily Last modified: \today}}
\rfoot{\color{black!60}{\sffamily\thepage}}



\begin{document}
\bibliographystyle{apalike}
\title{\large \bf GENERALIZED EXTREME VALUE DISTRIBUTIONS}
\author{\small ZHANGSHENG LAI}
\date{}
\maketitle

\section{Asymptotic Models}
\subsection{Model Formulation}
The model focuses on the statistical behaviour of $M_n = \max\{X_1,\ldots,X_n\}$ where all the $X_i$'s are independent and identically distributed with distribution function $F$. The distribution of $M_n$ can be derived exactly for all values of $n$
\begin{align}
\mathbb{P}\{M_n\leq z\} &= \mathbb{P}\{X_1\leq z , \ldots X_n \leq z\}\nonumber\\
&= \prod_{i=1}^{n}\mathbb{P}\{X_i\leq z\}\nonumber\\
&=\{F(z)\}^n \label{eq:maxofrv}
\end{align}

Although we know how to find the distribution of $M_n$ the maximum of iid random variables, not knowing what $F$ makes knowing the above not helpful. We could utilise standard statistical techniques like maximum likelihood to get an estimate $\widehat{F}$ from the observed data the substitute into (\ref{eq:maxofrv}). However small errors in the estimate of $F$ can lead to substantial errors in $F^n$.

The approach we are going to look at here is to accept that $F$ is unknown, instead of estimating $F$ to estimate $F^n$, we find an estimate of $F^n$ directly, which can be estimated using extreme data only. The idea is similar to the usual method of approximating the distribution of sample means by the normal distribution. So essentially we are doing the extreme value analogue of the central limit theory.

Observe that for a distribution function $F$ with upper end-point $z^+$, i.e. $F(z^+) = 1$ for any $z<z^+$, $F^n(z) \to 0$ as $n \to \infty$, thus $M_n$ degenerates to a point mass on $z^+$. To avoid this problem, we do a linear renormalization of the variable $M_n$:
\begin{align*}
M_n^\ast = \frac{M_n - b_n}{a_n}
\end{align*}
for a sequence of constants $\{a_n>0\}$ and $\{b_n\}$. By choosing appropriate $\{a_n\}$ and $\{b_n\}$ it stabilizes the location and scale of $M_n^\ast$ as $n$ grows avoiding problems of degeneracy. Thus we seek limit distributions of $M_n^\ast$ instead of $M_n$ with appropriate choices of $\{a_n\}$ and $\{b_n\}$.

\subsection{Extremal Types Theorem}

\begin{thm}[Fisher-Tippett-Gnedenko]\label{thm:gfw}
If there exists sequences of constants $\{a_n>0\}$ and $\{b_n\}$ such that 
\begin{align*}
\mathbb{P}\{M_n-b_n/a_n \leq z\} \to G(z) \quad \text{ as } n \to \infty
\end{align*}
where $G$ is a non-degenerate distribution function, then $G$ belongs to one of the following families:
\begin{align*}
\mathbb{I}:\quad G(z)\quad&= \quad\exp \left\{-\exp\left[-\left(\frac{z-b}{a}\right)\right]\right\}, \quad -\infty<z<\infty\\
\mathbb{II}: \quad G(z)\quad&= \quad\begin{cases}
0, & z \leq b\\
\exp\left\{-\left(\frac{z-b}{a}\right)^{-\alpha}\right\}, &z >b
\end{cases}
\\
%\mathbb{III}:\quad G(z)\quad&=  \quad\begin{cases}
%\exp\left\{-\left[-\left(\frac{z-b}{a}\right)^{-\alpha}\right]\right\}, & z \leq b\\
%1, &z >b
\mathbb{III}:\quad G(z)\quad&=  \quad\begin{cases}
\exp\left\{-\left(-\frac{z-b}{a}\right)^{\alpha}\right\}, & z \leq b\\
1, &z >b
\end{cases}
\end{align*}
for parameters $a>0, b$ and for families $\mathbb{II}, \mathbb{III}$, $\alpha >0$.
\end{thm}
These three classes of distribution are called \textbf{extreme value distributions} with the types $\mathbb{I},\mathbb{II}$ and $\mathbb{III}$ widely known as the \textbf{Gumbel}, \textbf{Fr\'echet} and \textbf{Weibull} families respectively. Theorem \ref{thm:gfw} implies that when $M_n$ can be stabilized with suitable sequences $\{a_n>0\}$ and $b_n$ the corresponding normalized $M_n^\ast$ has a limiting distribution that must be one of the three extreme distributions. It is in this sense that the theorem provides an extreme value analog of central limit theorem.

\subsection{The Generalized Extreme Value Distribution}
The three types of limits have different characteristic, corresponding to the different kind of tail behaviour for the distribution function $F$ of the $X_i$'s. We have the Gumbel to be unbounded, Fr\'echet bounded below and the Weibull bounded above. The density of Gumbel decays exponentially whereas it is polynomially for the Fr\'echet, corresponding to relative decay rates in the tail of $F$. Thus the different families give different representations of extreme value behaviour. Initially, extreme value theory was applied by choosing a family that is most suitable for the data we have and once the family was chosen, we assume that subsequent inferences be made based on the assumption that the choice of family is correct and do not allow for any uncertainty although there might be much uncertainty.

A much more flexible approach is to reformulate the three models into a single distribution which has the form,
\begin{align}\label{eq:gev}
G(x) = \exp \left\{-\left[1+\xi\left(\frac{x-\mu}{\sigma}\right)\right]^{-1/\xi}\right\}
\end{align}
defined on the set $\{x : 1 + \xi(x-\mu)/\sigma>0\}$ where the parameters satisfy $-\infty<\mu, \xi<\infty$ and $\sigma >0$. The above distribution is the generalized extreme value (GEV) family of distributions, where $\mu$ is the location parameter, $\sigma$ is the scale parameter and $\xi$ is the shape parameter. The type $\mathbb{II}$ and $\mathbb{III}$ classes correspond to the case where $\xi >0$ and $\xi<0$ respectively and the subset of the family with $\xi = 0$ is interpreted as the limit of (\ref{eq:gev}) as $\xi \to 0$.

\begin{thm}\label{thm:gev}
If there exists sequence of constants $\{a_n\}$ and $\{b_n\}$ such that 
\begin{align}\label{eq:gevlimit}
\mathbb{P}\{(M_n - b_n)/a_n\leq z\} \to G(z) \text{ as } n \to \infty
\end{align}
for a non-degenerate distribution function $G$, then $G$ is a member of the GEV family
\begin{align}
G(x) = \exp \left\{-\left[1+\xi\left(\frac{x-\mu}{\sigma}\right)\right]^{-1/\xi}\right\}
\end{align}
defined on the set $\{x : 1 + \xi(x-\mu)/\sigma>0\}$ where the parameters satisfy $-\infty<\mu, \xi<\infty$ and $\sigma >0$.
\end{thm}

By interpreting the limit in Theorem \ref{thm:gev} as an approximation for large values of $n$ suggests the use of the GEV family for modelling the distribution of maxima long sequences. With this result we can solve for the normalizing constants that are unknown is practice. Given (\ref{eq:gevlimit}) holds
\begin{align*}
\mathbb{P}\{(M_n-b_n)/a_n\leq z\} \approx G(z)
\end{align*}
for large $n$. With some manipulation 
\begin{align*}
\mathbb{P}\{(M_n-b_n)/a_n\leq z\} \approx G((z-b_n)/a_n) = G^\ast(z)
\end{align*}
where $G^\ast$ is another member of the GEV family. This says that we can approximate the distribution of $M_n^\ast$ by a member of the GEV for large $n$, we can do the same for the distribution of $M_n$. {\color{red} Since the parameters of the distribution have to be estimated anyway, it is irrelevant in practice that the parameters of the distribution of $G$ are different from those of $G^\ast$}. \textbf{Still got stuff on return level and period here!!}

\subsection{Outline Proof of the Extremal Types Theorem}

\begin{defn}
A distribution $G$ is said to be \textbf{max-stable} if, for every $n=2,3,\ldots$ there are constants $\alpha_n>0$ and $\beta_n$ such that
\begin{align*}
G^n(\alpha_nz+\beta_n) = G(z)
\end{align*}
\end{defn}

\begin{thm}\label{thm:maxstablegev}
A distribution is max-stable iff it is a generalized extreme value distribution.
\begin{proof}
We shall skip the forward direction proof as it utilizes machinery that are not trivial and show the converse. Let the Fr\'echet $G(x)$ be given, then 	
\begin{align*}
G^n(z) &= \exp\left\{-n\left(\frac{z-b}{a}\right)^{-\alpha}\right\}\\
&= \exp\left\{-\left(\frac{z-b}{an^{1/\alpha}}\right)^{-\alpha}\right\}\\
&=G(\alpha_nz+\beta_n)
%&=G(n^{-1/\alpha}z+(1 +  n^{-1/\alpha}))
\end{align*}
where $\alpha_n = n^{-1/\alpha}$ and $\beta_n = 1 +  n^{-1/\alpha}$. In a similar fashion we can prove it for Weibull. For Gumbel, we have
\begin{align*}
G^n(z) &= \exp\left\{-n\exp\left[-\left(\frac{z-b}{a}\right)\right]\right\} \\
&= \exp\left\{-\exp\Big(\log n\Big)\cdot\exp\left[-\left(\frac{z-b}{a}\right)\right]\right\}\\
&= \exp\left\{-\exp\left[\log n-\left(\frac{z-b}{a}\right)\right]\right\} \\
&=G(\alpha_nz+\beta_n)
\end{align*}
where $\alpha_n = 1$ and $\beta_n = -a\log n$.
\end{proof}
\end{thm}

Theorem \ref{thm:maxstablegev} is used directly in the proof of extremal types theorems. We start be considering $M_{nk}$, the maximum random variable in a sequence of $n \times k$ variables for some large value of $n$. This can be regarded as the maximum of a single sequence of length $n \times k$ or as the maximum of $k$ maxima, each of which is a maximum of $n$ observations. Let's assume that the limit distribution of $(M_n-b_n)/a_n$ is $G$, thus for sufficiently large $n$
\begin{align*}
\mathbb{P}\{(M_n-b_n)/a_n\} \approx G(z)
\end{align*}
Hence for any integer $k$ we also have 
\begin{align*}
\mathbb{P}\{(M_{nk}-b_{nk})/a_{nk}\} \approx G(z)
\end{align*}
but now we recall the definitions of $M_n$ and $M_{nk}$, we have 
\begin{align*}
G\left(\frac{z-b_{nk}}{a_{nk}}\right)\approx\mathbb{P}\{(M_{nk}-b_{nk})/a_{nk}\leq z\}=\left[\mathbb{P}\{(M_{n}-b_{n})/a_{n}\leq z\}\right]^k \approx G^k\left(\frac{z-b_n}{a_n}\right)
\end{align*}
Therefore $G$ and $G^k$ are identically apart except for location and scale coefficients. Thus $G$ is max-stable and a member of GEV by Theorem \ref{thm:maxstablegev}

\begin{defn}[Domain of Attraction]
A distribution $\mu$ is said to be in the domain of attraction of an extreme value distribution $\nu$ (either Gumbel, Fr\'echet or Weibull) denoted by $\mu \in \mathcal{D}(\nu) $ if there exists $\{a_n>0\}$ and $\{b_n\}$ such that the distribution of $(M_n-b_n)/a_n$ converges weakly to $\nu$, where $M_n:=\max_{1\leq i \leq n}X_i$ for an independent and identically distributed sequence $X_1, X_2, \ldots$ with distribution $\mu$.
\end{defn}

\begin{examp}
If $X_1, X_2, \ldots$ is a sequence of independent and identically distributed $\text{\sffamily Exp}(1)$ random variables, $F(x) = 1-e^{-x}$ for $x>0$, choosing $a_n = 1$ and $b_n = \log n$
\begin{align*}
\mathbb{P}\{(M_n-b_n)/a_n\} &= F^n(z + \log n)\\
&= \bigg[1-e^{-(z+\log n)}\bigg]^n\\
&= \bigg[1-n^{-1}e^{-z}\bigg]^n \to \exp(-e^{-z}) \text{ as } n \to \infty
\end{align*}
here we use the fact that $\lim_{n \to \infty} \left(1-\frac{1}{n}\right)^n = \frac{1}{e}$. Hence with the chosen $a_n$ and $b_n$, the limit of $M_n$ converges to the Gumbel distribution as $n \to \infty$. This corresponds to $\xi = 0$ in the GEV family. \eqed
\end{examp}

\begin{examp}
If $X_1, X_2, \ldots$ is a sequence of independent Fr\'echet variables. $F(x) = \exp(-1/x)$ for $x>0$. Letting $a_n = n$ and $b_n = 0$
\begin{align*}
\mathbb{P}\{(M_n-b_n)/a_n\leq z\}  & = F^n(nz)\\
& = \Big[\exp\{-1/nz\}\Big]^n\\
& = \exp(-1/z)
\end{align*}
as $n \to \infty$, for each $z>0$. Hence the limit in this case which is an exact result for all $n$ since the Fr\'echet is max-stable is also the Fr\'echet distribution. This corresponds to $\xi = 1$ in the GEV family.
\eqed
\end{examp}

\begin{examp}
If $X_1, X_2, \ldots$ are a sequence of independent uniform $\text{\sffamily U}(0,1)$ variables, $F(x)=x$ for $0 \leq x \leq 1$. For fixed $z < 0$, suppose $n>-z$ and let $a_n = 1/n$ and $b_n = 1$. Then
\begin{align*}
\mathbb{P}\{(M_n-b_n)/a_n\leq z\} &= F^n(n^{-1}z+1)\\
&= \left(1+\frac{z}{n}\right)^n\\
&\to e^z \text{ as } n \to \infty
\end{align*}
Hence the distribution is Weibull type with $\xi=-1$ in the GEV family.
\eqed
\end{examp}

\subsection{Inference for the GEV distribution}
\subsubsection{General Considerations}



\subsubsection{Maximum Likelihood Estimation}


%\section{Hill's Estimator}
%The motivation of this paper came from considering a random sample $Z_1, \ldots, Z_k$ from a distribution of $F$ from a unit interval with $F(x) \sim Cx^\alpha$ as $x\to 0$. We would also like to be able to draw inference about $\alpha$ without making assumptions about the form of $F$ elsewhere.
%
%Suppose that a sample $Y_1,\ldots,Y_k$ is drawn from the population with distribution $G$ and let 
%\begin{align*}
%Y^{(1)} \geq Y^{(2)} \geq \ldots \geq Y^{(k)}
%\end{align*}
%be the order statistics. On the basis of theoretical arguments or previous data, it is believed, or at least the hypothesis is tentatively entertained, that $G$ has a known functional form, say $G(y) = w(y;\theta)$, for \emph{$y$ sufficiently large} and $\theta$ be a vector of parameters. The simplest case is that in which a number $D$ is known such that for $y \geq D$ this functional form is valid. Here $D$ need not be the smallest value for which this is true, and thus might be chosen quite conservatively in some situations. When the global form of $G$ is unknown, so that ordinary parametric models are unavailable, it is then perhaps intuitively plausible to base inference about $\theta$ on the order statistics that exceed $D$, since it is only these that lie in the region where $G$ is believed to have the specific form. Thus the values of such order statistics might be taken as a conditioning event, or data, for the purpose of inference about $\theta$. In typical applications $D$ will not be known precisely and it will be necessarily to select a subset, consisting of the $\hat{r}+1$ largest order statistics, on the basis of prior knowledge and a combination of various data analytic techniques. Such an $\hat{r}$ will often depend upon the data in a highly complicated way, and questions as to the precise form of conditioning event become of lesser importance than the choice of $\hat{r}$. The approach advocated here is to consider the inference based upon the values of the $r+1$ largest order statistics, for $r = 1, 2, \ldots$, until upon the basis of data analytic guides and prior knowledge a stopping point $\hat{r}$ is reached, beyond which it is unwise to proceed.



%\cite{hill1975simple}
%	\bibliography{evt}

\end{document}