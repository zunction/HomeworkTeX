\documentclass[a4paper,10pt]{article}
\setlength{\parindent}{0cm}
\usepackage{amsmath, amssymb, amsthm, mathtools,pgfplots}
\usepackage{graphicx,caption}
\usepackage{verbatim}
\usepackage{venndiagram}
\usepackage[cm]{fullpage}
\usepackage{fancyhdr}
\usepackage{tikz}
\usepackage{listings,url,}
\usepackage{color,enumerate,framed}
\usepackage{color,hyperref}
\definecolor{darkblue}{rgb}{0.0,0.0,0.5}
\hypersetup{colorlinks,breaklinks,
            linkcolor=darkblue,urlcolor=darkblue,
            anchorcolor=darkblue,citecolor=darkblue}

\usepackage{sectsty}
\allsectionsfont{\centering}
%\usepackage[normalem]{ulem}
%\allsectionsfont{\sffamily}
%\sectionfont{\centering\ulemheading{\uuline}}

%\usepackage{tgadventor}
%\usepackage[nohug]{diagrams}
\usepackage[T1]{fontenc}
%\usepackage{helvet}
%\renewcommand{\familydefault}{\sfdefault}
%\usepackage{parskip}
%\usepackage{picins} %for \parpic.
%\newtheorem*{notation}{Notation}
%\newtheorem{example}{Example}[section]
%\newtheorem*{problem}{Problem}
\theoremstyle{definition}
%\newtheorem{theorem}{Theorem}
%\newtheorem*{solution}{Solution}
%\newtheorem*{definition}{Definition}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem*{remark}{Remark}
%\setcounter{section}{1}

\newtheorem{thm}{Theorem}[section]
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{defn}[thm]{Definition}
\newtheorem*{examp}{Example}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{rmk}[thm]{Remark}
\newtheorem*{nte}{Note}
\newtheorem*{notat}{Notation}

%\diagramstyle[labelstyle=\scriptstyle]

\lstset{frame=tb,
  language=Oz,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}


\pagestyle{fancy}




\fancyhead{}
\renewcommand{\headrulewidth}{0pt}

\lfoot{\color{black!60}{\sffamily Zhangsheng Lai}}
\cfoot{}
\cfoot{\color{black!60}{\sffamily Last modified: \today}}
\rfoot{\color{black!60}{\textsc{\thepage}}}



\begin{document}
%\flushright{Zhangsheng Lai\\1002554}
\section*{Review: Building Adversary Resistant Deep Neural Networks with Random Feature Nullification}
\subsection*{Summary}
The paper presents the random feature nullification to preserve the DNN's integrity against adversarial samples. Based on the discussion on the related work to increase the DNN's resistance to adversarial samples, the non-deterministic technique introduced is a nature progression from the current available techniques of adversarial training and model complexity enhancement. (weakness of adversarial training and model complexity enhancement here?) The paper points out that to be able to put up a strong resistance against adversarial attacks, the model architecture has to be one makes it impossible to generate adversarial samples even when it is disclosed.





\subsection*{Positivity}

- the introduced method is more efficient than the method of adversarial training; there is no need to train on both the real sample and a crafted adversarial sample. The 

- 


\subsection*{Negativity}

\subsection*{My Thoughts}
- how does the techique to create adversarial samples work? How do we add the perturbation to make the DNN believe that it is of a particular class $A$ or $B$ when it is actually of class $C$?


- why compute  $\frac{\partial \mathcal{L}(\theta, f(\tilde{X},I_p),Y)}{\partial \tilde{X}}$ instead of  $\frac{\partial \mathcal{L}(\theta, f(\tilde{X},I_p),Y)}{\partial  f(\tilde{X},I_p)}$? Would seeing the data as $f(\tilde{X},I_p)$  be better than seeing it as $\tilde{X}$? Or perhaps I should first myself if that derivative can be computed. (my tentative answer is yes). Although $I_p$ is a random variable, what it does is that it nullifies every sample to 0 with proportion $p$. This can be seen as a form of occlusion with the image being occluded at many small spots.

- is $\delta X \odot I_p^\ast$ a notation or the exact representation of the perturbation?

- can the attacker not draw a sample $I_p^\ast$ which then the nullified adversarial sample looks like
\begin{align*}
(X+\delta X {\color{black!30}\odot I_p^\ast}) \odot I_p = (X \odot I_p) + \delta X {\color{black!30}\odot I_p^\ast} \odot I_p
\end{align*}
%- the paper says that $\frac{\partial f(\tilde{X},I_p)}{\partial \tilde{X}}$ is computationally impossible due to the randomness of $I_p$ and thus for the attackers to compute this derivate to produce an adversarial perturbation attackers have to use a random $I_p^\ast$ to approximate the initial $I_p$ used. However, since the random nullification nullifies the inputs to 0, attackers can use the 

%- attackers can try to synthesis the $I_p$ matrix by examining the 

- could explore deeper on how attackers can bypass the random feature nullification technique other than the traditional method used by them to produce adversarial samples.

- could have tested it on CIFAR dataset since MNIST dataset is a smaller space than the CIFAR dataset and this technique might not work as well on images with more colors and variety. There are papers that the author cited from that discussed about adversarial examples in other datasets.
%\cite{goodfellow2014explaining}
%\cite{tesla}
\newpage

\bibliography{review} 
\bibliographystyle{apalike}













\end{document}